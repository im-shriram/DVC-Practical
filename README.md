<h1 align="center">ğŸš€ DVC Pipeline Tutorial</h1>

<p align="center">
  <em>A complete Machine Learning pipeline powered by <strong>Data Version Control (DVC)</strong></em>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.8+-3776AB.svg?style=flat-square&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/scikit--learn-ML-F7931E?style=flat-square&logo=scikit-learn&logoColor=white" alt="Sklearn">
  <img src="https://img.shields.io/badge/DVCLive-Tracking-945DD6?style=flat-square" alt="DVCLive">
</p>

---

## ğŸ“– Overview

This project demonstrates a **production-ready ML pipeline** using [DVC (Data Version Control)](https://dvc.org/) for data versioning, pipeline orchestration, and experiment tracking. The pipeline performs **text classification** using a Bagging Classifier with comprehensive preprocessing and feature engineering stages.

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ”„ **Reproducible Pipelines** | Fully automated ML pipeline with DVC stages |
| ğŸ“Š **Experiment Tracking** | DVCLive integration for metrics & plots |
| ğŸ§ª **Version Control** | Data, models, and experiments versioned with DVC |
| ğŸ“ˆ **Visualizations** | Confusion matrix & precision-recall curves |
| âš™ï¸ **Configurable** | Centralized parameters via `params.yaml` |

---

## ğŸ—ï¸ Project Structure

```
ğŸ“¦ DVC
â”œâ”€â”€ ğŸ“‚ data/                    # Data directory (DVC tracked)
â”‚   â”œâ”€â”€ ğŸ“ raw/                 # Original, immutable data
â”‚   â”œâ”€â”€ ğŸ“ interim/             # Intermediate transformed data
â”‚   â”œâ”€â”€ ğŸ“ processed/           # Cleaned data for modeling
â”‚   â”œâ”€â”€ ğŸ“ features/            # Final feature sets (train/test)
â”‚   â””â”€â”€ ğŸ“ external/            # External data sources
â”‚
â”œâ”€â”€ ğŸ“‚ src/                     # Source code for the pipeline
â”‚   â”œâ”€â”€ ğŸ“ data/                # Data ingestion scripts
â”‚   â”‚   â””â”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ ğŸ“ features/            # Feature engineering
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ ğŸ“ models/              # Model training & evaluation
â”‚   â”‚   â”œâ”€â”€ train_model.py
â”‚   â”‚   â””â”€â”€ evaluate_model.py
â”‚   â””â”€â”€ ğŸ“ visualization/       # Visualization utilities
â”‚
â”œâ”€â”€ ğŸ“‚ models/                  # Trained models & artifacts
â”‚   â”œâ”€â”€ ğŸ“ models/              # Serialized model files
â”‚   â””â”€â”€ ğŸ“ vectorizers/         # Feature vectorizers (BoW)
â”‚
â”œâ”€â”€ ğŸ“‚ dvclive/                 # Experiment tracking outputs
â”‚   â”œâ”€â”€ metrics.json            # Model metrics
â”‚   â”œâ”€â”€ params.yaml             # Tracked parameters
â”‚   â””â”€â”€ ğŸ“ plots/               # Generated visualizations
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/               # Jupyter notebooks for EDA
â”œâ”€â”€ ğŸ“‚ docs/                    # Documentation (Sphinx)
â”œâ”€â”€ ğŸ“‚ reports/                 # Generated analysis reports
â”‚
â”œâ”€â”€ ğŸ“„ dvc.yaml                 # DVC pipeline definition
â”œâ”€â”€ ğŸ“„ dvc.lock                 # Pipeline state lock file
â”œâ”€â”€ ğŸ“„ params.yaml              # Hyperparameters & config
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â”œâ”€â”€ ğŸ“„ Makefile                 # Automation commands
â””â”€â”€ ğŸ“„ setup.py                 # Package setup
```

---

## ğŸ” Pipeline Architecture

```mermaid
flowchart LR
    subgraph Data["ğŸ“¥ Data Layer"]
        A[("ğŸ—ƒï¸ Raw Data")] --> B["âš™ï¸ Data Ingestion"]
    end
    
    subgraph Features["ğŸ”§ Feature Engineering"]
        B --> C["ğŸ§¹ Preprocessing"]
        C --> D["ğŸ“ Feature Engineering"]
    end
    
    subgraph Model["ğŸ¤– Model Layer"]
        D --> E["ğŸ¯ Model Training"]
        E --> F["ğŸ“Š Evaluation"]
    end
    
    subgraph Outputs["ğŸ“¤ Outputs"]
        F --> G[("ğŸ“ˆ Metrics")]
        F --> H[("ğŸ–¼ï¸ Plots")]
        E --> I[("ğŸ’¾ Model")]
    end
    
    style A fill:#e1f5fe,color:#000
    style I fill:#c8e6c9,color:#000
    style G fill:#fff3e0,color:#000
    style H fill:#fce4ec,color:#000
```

### Pipeline Stages

| Stage | Script | Description |
|-------|--------|-------------|
| **1. Data Ingestion** | `data_ingestion.py` | Split raw data into train/test sets |
| **2. Preprocessing** | `data_preprocessing.py` | Text cleaning & normalization |
| **3. Feature Engineering** | `feature_engineering.py` | Bag-of-Words vectorization |
| **4. Model Training** | `train_model.py` | Train Bagging Classifier |
| **5. Model Evaluation** | `evaluate_model.py` | Generate metrics & visualizations |

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Git
- DVC

### Installation

```bash
# 1. Clone the repository
git clone <repository-url>
cd DVC

# 2. Create virtual environment
python -m venv myenv
source myenv/bin/activate  # On Windows: myenv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Pull DVC tracked data (if using remote storage)
dvc pull
```

### Running the Pipeline

```bash
# Run entire pipeline
dvc repro

# Run specific stage
dvc repro data_ingestion

# View pipeline DAG
dvc dag
```

---

## âš™ï¸ Configuration

All hyperparameters are centralized in `params.yaml`:

```yaml
data_ingestion:
  seed: 42
  test_size: 0.25

feature_engineering:
  max_features: 100

model_training:
  estimator:              # Decision Tree params
    max_depth: 25
    min_samples_split: 10
    min_samples_leaf: 5
  bagging:                # Bagging Classifier params
    n_estimators: 250
    max_samples: 0.75
```

---

## ğŸ“Š Experiment Tracking

This project uses **DVCLive** for experiment tracking:

```bash
# View experiments
dvc exp show

# Compare experiments
dvc exp diff

# Run experiment with modified params
dvc exp run -S model_training.bagging.n_estimators=300
```

### Tracked Metrics & Plots

- âœ… **Confusion Matrix** - Classification performance visualization
- âœ… **Precision-Recall Curve** - Model threshold analysis
- âœ… **Metrics JSON** - Accuracy, Precision, Recall, F1-Score

---

## ğŸ› ï¸ Make Commands

```bash
make requirements    # Install dependencies
make clean          # Remove compiled Python files
make lint           # Run flake8 linting
make data           # Generate processed dataset
make help           # Show all available commands
```

---

## ğŸ“ Artifacts

| Artifact | Path | Type |
|----------|------|------|
| Training Dataset | `data/features/train.csv` | Dataset |
| Test Dataset | `data/features/test.csv` | Dataset |
| Bagging Classifier | `models/models/bagging_classifier.joblib` | Model |
| BoW Vectorizer | `models/vectorizers/bow.joblib` | Vectorizer |

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  Made with â¤ï¸ using <a href="https://dvc.org/">DVC</a> | <a href="https://scikit-learn.org/">Scikit-learn</a> | <a href="https://www.python.org/">Python</a>
</p>